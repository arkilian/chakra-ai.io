# ChakraAgents.ai - DocumentaÃ§Ã£o Completa

> **IA AgÃªntica como ServiÃ§o**  
> Plataforma open-source para construir, testar e implementar fluxos de trabalho de agentes de IA

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [CaracterÃ­sticas Principais](#caracterÃ­sticas-principais)
- [Arquiteturas Suportadas](#arquiteturas-suportadas)
- [Requisitos do Sistema](#requisitos-do-sistema)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Arquitetura do Sistema](#arquitetura-do-sistema)
- [Guias de UtilizaÃ§Ã£o](#guias-de-utilizaÃ§Ã£o)
- [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
- [ReferÃªncia da API](#referÃªncia-da-api)
- [ResoluÃ§Ã£o de Problemas](#resoluÃ§Ã£o-de-problemas)
- [Contribuir](#contribuir)
- [LicenÃ§a](#licenÃ§a)

## ğŸ¯ VisÃ£o Geral

**ChakraAgents.ai** Ã© uma plataforma completa para desenvolvimento de sistemas de IA agÃªntica, permitindo criar agentes autÃ³nomos capazes de tomar decisÃµes, raciocinar e executar tarefas complexas. A plataforma integra-se com os principais fornecedores de LLM (Large Language Models) e suporta mÃºltiplas arquiteturas de agentes.

### O Que Ã© IA AgÃªntica?

IA agÃªntica refere-se a sistemas de inteligÃªncia artificial capazes de:
- **Autonomia**: Tomar decisÃµes de forma independente
- **RaciocÃ­nio**: Analisar problemas e planear soluÃ§Ãµes
- **Aprendizagem**: Adaptar-se com base em experiÃªncias
- **ColaboraÃ§Ã£o**: Trabalhar com outros agentes para objetivos comuns

## âœ¨ CaracterÃ­sticas Principais

### 1. **Editor Visual de Fluxos de Trabalho**
Interface intuitiva para desenhar e orquestrar fluxos de trabalho de agentes sem necessidade de programaÃ§Ã£o extensa.

### 2. **Capacidades RAG (Retrieval-Augmented Generation)**
Conecte os seus agentes a:
- Bases de dados de documentos privados
- RepositÃ³rios de conhecimento empresarial
- Sistemas de armazenamento vetorial
- Fontes de dados personalizadas

### 3. **MÃºltiplas Arquiteturas de Agentes**
Suporte nativo para diferentes padrÃµes arquiteturais:
- **Supervisor**: Arquitetura hierÃ¡rquica
- **Swarm**: ColaboraÃ§Ã£o peer-to-peer
- **RAG**: Agentes aumentados com conhecimento

### 4. **ImplementaÃ§Ã£o de API**
Transforme fluxos de trabalho de agentes em endpoints API robustos e escalÃ¡veis.

### 5. **MonitorizaÃ§Ã£o e AnÃ¡lise**
Acompanhe:
- Desempenho dos agentes
- UtilizaÃ§Ã£o de recursos
- MÃ©tricas de sucesso
- Custos operacionais

### 6. **IntegraÃ§Ã£o com Principais LLMs**
Suporte para:
- OpenAI (GPT-4, GPT-3.5, etc.)
- Anthropic (Claude)
- Google Vertex AI
- Modelos personalizados

## ğŸ—ï¸ Arquiteturas Suportadas

### Arquitetura Supervisor

**DescriÃ§Ã£o**: Sistema hierÃ¡rquico onde um agente supervisor coordena agentes trabalhadores especializados.

**Vantagens**:
- âœ… Controlo centralizado e previsÃ­vel
- âœ… GestÃ£o de contexto e memÃ³ria simplificada
- âœ… Encaminhamento claro de tarefas
- âœ… Ideal para processos sequenciais

**Desvantagens**:
- âŒ PossÃ­vel gargalo no supervisor
- âŒ Menos flexibilidade adaptativa
- âŒ Ponto Ãºnico de falha

**Casos de Uso**:
- Triagem de suporte ao cliente
- Processamento de documentos com mÃºltiplas etapas
- Fluxos de trabalho regulamentados
- OrquestraÃ§Ã£o de tarefas complexas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supervisor â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚         â”‚         â”‚         â”‚
   â”Œâ”€â”€â–¼â”€â”€â”   â”Œâ”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â–¼â”€â”€â”
   â”‚Agentâ”‚   â”‚Agentâ”‚  â”‚Agentâ”‚   â”‚Agentâ”‚
   â”‚  1  â”‚   â”‚  2  â”‚  â”‚  3  â”‚   â”‚  4  â”‚
   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜
```

### Arquitetura Swarm

**DescriÃ§Ã£o**: MÃºltiplos agentes colaboram como pares, com coordenaÃ§Ã£o descentralizada.

**Vantagens**:
- âœ… Alta tolerÃ¢ncia a falhas
- âœ… Escalabilidade natural
- âœ… Comportamento emergente e adaptativo
- âœ… DistribuiÃ§Ã£o eficiente de carga

**Desvantagens**:
- âŒ Rastreamento complexo de decisÃµes
- âŒ GestÃ£o de estado mais elaborada
- âŒ PossÃ­vel necessidade de afinaÃ§Ã£o

**Casos de Uso**:
- Sistemas multi-domÃ­nio de perguntas e respostas
- AnÃ¡lise colaborativa de dados
- ResoluÃ§Ã£o de problemas complexos
- CenÃ¡rios com tarefas ambÃ­guas

```
   â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”
   â”‚Agent â”‚â—„â”€â”€â”€â–ºâ”‚Agent â”‚
   â”‚  1   â”‚     â”‚  2   â”‚
   â””â”€â”€â”€â–²â”€â”€â”˜     â””â”€â”€â–²â”€â”€â”€â”˜
       â”‚   â•²   â•±   â”‚
       â”‚    â•³ â•³    â”‚
       â”‚   â•±   â•²   â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”     â”Œâ”€â”€â–¼â”€â”€â”€â”
   â”‚Agent â”‚â—„â”€â”€â”€â–ºâ”‚Agent â”‚
   â”‚  3   â”‚     â”‚  4   â”‚
   â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura RAG (Retrieval-Augmented Generation)

**DescriÃ§Ã£o**: Agentes aumentados com capacidade de recuperaÃ§Ã£o e sÃ­ntese de informaÃ§Ã£o de fontes de conhecimento privadas.

**CaracterÃ­sticas**:
- ğŸ” Pesquisa semÃ¢ntica em documentos
- ğŸ“š IntegraÃ§Ã£o com bases de conhecimento
- ğŸ¯ Respostas baseadas em fontes verificÃ¡veis
- ğŸ”„ AtualizaÃ§Ã£o dinÃ¢mica de conhecimento

**Componentes**:
1. **Vector Store**: Armazena embeddings de documentos
2. **Retriever**: Recupera documentos relevantes
3. **LLM**: Gera respostas baseadas no contexto
4. **Synthesizer**: Combina informaÃ§Ãµes de mÃºltiplas fontes

**Casos de Uso**:
- Assistentes de documentaÃ§Ã£o empresarial
- Sistemas de conformidade e compliance
- Suporte tÃ©cnico baseado em manuais
- AnÃ¡lise de grandes volumes de documentos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Query    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retriever  â”‚â—„â”€â”€â”€â”€â–ºâ”‚  Vector Store  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LLM     â”‚â—„â”€â”€â”€â”€â–ºâ”‚   Documents    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’» Requisitos do Sistema

### Requisitos MÃ­nimos

- **Python**: 3.10 ou superior
- **Node.js**: 16.x ou superior
- **PostgreSQL**: 12.x ou superior (para produÃ§Ã£o)
- **MemÃ³ria RAM**: MÃ­nimo 4GB (recomendado 8GB)
- **EspaÃ§o em Disco**: MÃ­nimo 2GB

### DependÃªncias Opcionais

- **Docker**: Para implementaÃ§Ã£o containerizada
- **Redis**: Para cache e gestÃ£o de filas
- **Nginx**: Para proxy reverso em produÃ§Ã£o

## ğŸš€ InstalaÃ§Ã£o

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/sudsk/ChakraAgents.ai.git
cd ChakraAgents.ai
```

### 2. ConfiguraÃ§Ã£o do Backend

```bash
# Navegar para o diretÃ³rio backend
cd backend

# Criar ambiente virtual Python
python -m venv venv

# Ativar ambiente virtual
# No Linux/Mac:
source venv/bin/activate
# No Windows:
# venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt

# Copiar ficheiro de configuraÃ§Ã£o
cp .env.example .env

# Editar .env com as suas configuraÃ§Ãµes
nano .env  # ou use o seu editor preferido

# Executar migraÃ§Ãµes da base de dados
alembic upgrade head

# Iniciar servidor backend
uvicorn app.main:app --reload
```

O backend estarÃ¡ disponÃ­vel em: `http://localhost:8000`

### 3. ConfiguraÃ§Ã£o do Frontend

```bash
# Abrir nova janela de terminal e navegar para o diretÃ³rio frontend
cd frontend

# Instalar dependÃªncias
npm install

# Copiar ficheiro de configuraÃ§Ã£o
cp .env.example .env

# Editar .env com as suas configuraÃ§Ãµes
nano .env

# Iniciar servidor de desenvolvimento
npm start
```

O frontend estarÃ¡ disponÃ­vel em: `http://localhost:3000`

### 4. VerificaÃ§Ã£o da InstalaÃ§Ã£o

Aceda a `http://localhost:3000` no seu navegador. DeverÃ¡ ver a interface do ChakraAgents.ai.

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente - Backend

Crie um ficheiro `.env` no diretÃ³rio `backend/` com as seguintes configuraÃ§Ãµes:

```env
# Base de Dados
POSTGRES_URI=postgresql://utilizador:palavra-passe@localhost:5432/chakraagents
DATABASE_URL=${POSTGRES_URI}

# Chaves API dos LLMs
OPENAI_API_KEY=sk-your-openai-api-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
GOOGLE_APPLICATION_CREDENTIALS=/caminho/para/credenciais.json

# Vector Store (opcional)
VECTOR_STORE_TYPE=chroma  # ou 'faiss', 'pinecone', 'weaviate'
VECTOR_STORE_CONNECTION=http://localhost:8001

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# SeguranÃ§a
SECRET_KEY=gere-uma-chave-secreta-forte-aqui
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ConfiguraÃ§Ãµes de Log
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Redis (opcional)
REDIS_URL=redis://localhost:6379/0
```

### VariÃ¡veis de Ambiente - Frontend

Crie um ficheiro `.env` no diretÃ³rio `frontend/` com as seguintes configuraÃ§Ãµes:

```env
# URL da API Backend
REACT_APP_API_URL=http://localhost:8000

# Funcionalidades
REACT_APP_FEATURE_RAG=true
REACT_APP_FEATURE_SWARM=true
REACT_APP_FEATURE_SUPERVISOR=true

# Analytics (opcional)
REACT_APP_GA_TRACKING_ID=UA-XXXXXXXXX-X

# Ambiente
REACT_APP_ENV=development
```

### ConfiguraÃ§Ã£o da Base de Dados

#### PostgreSQL

```bash
# Criar base de dados
createdb chakraagents

# Ou via psql
psql -U postgres
CREATE DATABASE chakraagents;
CREATE USER chakra_user WITH PASSWORD 'sua_palavra_passe';
GRANT ALL PRIVILEGES ON DATABASE chakraagents TO chakra_user;
```

### ConfiguraÃ§Ã£o de Vector Store

#### ChromaDB (Recomendado para Desenvolvimento)

```bash
pip install chromadb
```

```python
# No seu cÃ³digo Python
import chromadb

client = chromadb.Client()
collection = client.create_collection("documentos")
```

#### FAISS (Alternativa Local)

```bash
pip install faiss-cpu  # ou faiss-gpu para GPU
```

#### Pinecone (Cloud)

```bash
pip install pinecone-client
```

## ğŸ›ï¸ Arquitetura do Sistema

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                      â”‚
â”‚                  Interface de Utilizador                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ HTTP/REST
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Gateway                             â”‚
â”‚          (AutenticaÃ§Ã£o, Rate Limiting)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend   â”‚ â”‚   Vector    â”‚ â”‚   LLM        â”‚
â”‚  (FastAPI) â”‚ â”‚   Store     â”‚ â”‚   Providers  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL   â”‚
â”‚   (Database)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

**Frontend**:
- React 18.x
- Chakra UI (componentes de interface)
- Redux Toolkit (gestÃ£o de estado)
- Axios (cliente HTTP)
- React Router (navegaÃ§Ã£o)

**Backend**:
- FastAPI (framework web)
- LangChain (orquestraÃ§Ã£o de LLM)
- LangGraph (fluxos de trabalho de agentes)
- SQLAlchemy (ORM)
- Alembic (migraÃ§Ãµes)
- Pydantic (validaÃ§Ã£o de dados)

**Base de Dados**:
- PostgreSQL (dados relacionais)
- Redis (cache, filas)

**Vector Stores**:
- ChromaDB
- FAISS
- Pinecone
- Weaviate

## ğŸ“š Guias de UtilizaÃ§Ã£o

### Criar o Seu Primeiro Agente

#### 1. Agente Simples

```python
from langchain.agents import initialize_agent, Tool
from langchain.llms import OpenAI

# Inicializar LLM
llm = OpenAI(temperature=0)

# Definir ferramentas
ferramentas = [
    Tool(
        name="Pesquisa",
        func=lambda x: f"Resultado para: {x}",
        description="Ãštil para pesquisar informaÃ§Ã£o"
    )
]

# Criar agente
agente = initialize_agent(
    ferramentas,
    llm,
    agent="zero-shot-react-description",
    verbose=True
)

# Executar
resposta = agente.run("Qual Ã© a capital de Portugal?")
print(resposta)
```

#### 2. Agente com RAG

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# Carregar documentos
from langchain.document_loaders import TextLoader
loader = TextLoader("documentos/info.txt")
documentos = loader.load()

# Criar vector store
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documentos, embeddings)

# Criar chain RAG
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

# Fazer pergunta
resposta = qa.run("Qual Ã© a informaÃ§Ã£o sobre o produto X?")
print(resposta)
```

#### 3. Arquitetura Supervisor

```python
from langgraph.graph import Graph
from langchain.llms import OpenAI

# Definir agentes trabalhadores
class AgenteAnalise:
    def executar(self, entrada):
        return "AnÃ¡lise completa"

class AgenteExecucao:
    def executar(self, entrada):
        return "ExecuÃ§Ã£o completa"

# Criar supervisor
class Supervisor:
    def __init__(self):
        self.agentes = {
            "analise": AgenteAnalise(),
            "execucao": AgenteExecucao()
        }
    
    def delegar(self, tarefa):
        # LÃ³gica de delegaÃ§Ã£o
        if "analisar" in tarefa.lower():
            return self.agentes["analise"].executar(tarefa)
        else:
            return self.agentes["execucao"].executar(tarefa)

# Usar
supervisor = Supervisor()
resultado = supervisor.delegar("Analisar dados de vendas")
```

#### 4. Arquitetura Swarm

```python
class AgenteSwarm:
    def __init__(self, nome, especialidade):
        self.nome = nome
        self.especialidade = especialidade
    
    def processar(self, tarefa):
        # Processar tarefa
        return f"{self.nome} processou: {tarefa}"
    
    def colaborar(self, outros_agentes, tarefa):
        # Colaborar com outros agentes
        resultados = [self.processar(tarefa)]
        for agente in outros_agentes:
            resultados.append(agente.processar(tarefa))
        return self.sintetizar(resultados)
    
    def sintetizar(self, resultados):
        return f"SÃ­ntese de {len(resultados)} contribuiÃ§Ãµes"

# Criar swarm
agentes = [
    AgenteSwarm("Agente1", "AnÃ¡lise Financeira"),
    AgenteSwarm("Agente2", "AnÃ¡lise TÃ©cnica"),
    AgenteSwarm("Agente3", "AnÃ¡lise de Mercado")
]

# Colaborar
resultado = agentes[0].colaborar(agentes[1:], "Avaliar investimento")
```

### Implementar API

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

class Pergunta(BaseModel):
    texto: str
    contexto: str = None

@app.post("/api/agente/perguntar")
async def perguntar(pergunta: Pergunta):
    try:
        # Processar com agente
        resposta = agente.run(pergunta.texto)
        return {"resposta": resposta, "sucesso": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/agente/estado")
async def obter_estado():
    return {
        "ativo": True,
        "modelo": "gpt-4",
        "versao": "1.0.0"
    }
```

## ğŸ’¡ Exemplos PrÃ¡ticos

### Exemplo 1: Assistente de DocumentaÃ§Ã£o

```python
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.llms import OpenAI

# Carregar documentos
loader = DirectoryLoader("./docs", glob="**/*.md")
documentos = loader.load()

# Dividir em chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = text_splitter.split_documents(documentos)

# Criar vectorstore
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

# Criar chain conversacional
qa_chain = ConversationalRetrievalChain.from_llm(
    OpenAI(temperature=0),
    vectorstore.as_retriever(),
    return_source_documents=True
)

# Usar
chat_history = []
pergunta = "Como instalar a aplicaÃ§Ã£o?"
resultado = qa_chain({"question": pergunta, "chat_history": chat_history})
print(resultado["answer"])
```

### Exemplo 2: Sistema de Triagem de Suporte

```python
from langchain.agents import initialize_agent, Tool
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferMemory

class SistemaTriagem:
    def __init__(self):
        self.categorias = {
            "tecnico": "Equipa TÃ©cnica",
            "faturacao": "Equipa Financeira",
            "comercial": "Equipa de Vendas"
        }
    
    def categorizar(self, pergunta):
        # LÃ³gica de categorizaÃ§Ã£o
        llm = OpenAI(temperature=0)
        prompt = f"""
        Categorize a seguinte pergunta em uma destas categorias:
        - tecnico
        - faturacao
        - comercial
        
        Pergunta: {pergunta}
        Categoria:
        """
        categoria = llm(prompt).strip().lower()
        return self.categorias.get(categoria, "Equipa Geral")
    
    def criar_ticket(self, pergunta, categoria):
        return {
            "id": "TICKET-001",
            "pergunta": pergunta,
            "equipa": categoria,
            "prioridade": "normal",
            "estado": "aberto"
        }

# Usar
sistema = SistemaTriagem()
pergunta = "O meu servidor nÃ£o estÃ¡ a responder"
categoria = sistema.categorizar(pergunta)
ticket = sistema.criar_ticket(pergunta, categoria)
print(f"Ticket criado: {ticket}")
```

### Exemplo 3: AnÃ¡lise Colaborativa Multi-Agente

```python
from typing import List, Dict

class AgenteAnalitico:
    def __init__(self, nome: str, especialidade: str):
        self.nome = nome
        self.especialidade = especialidade
        self.llm = OpenAI(temperature=0.7)
    
    def analisar(self, dados: str) -> Dict:
        prompt = f"""
        Como especialista em {self.especialidade}, analise os seguintes dados:
        
        {dados}
        
        ForneÃ§a insights especÃ­ficos da sua Ã¡rea de especialidade.
        """
        analise = self.llm(prompt)
        return {
            "agente": self.nome,
            "especialidade": self.especialidade,
            "analise": analise
        }

class Sintetizador:
    def __init__(self):
        self.llm = OpenAI(temperature=0.3)
    
    def sintetizar(self, analises: List[Dict]) -> str:
        texto_analises = "\n\n".join([
            f"{a['especialidade']}: {a['analise']}"
            for a in analises
        ])
        
        prompt = f"""
        Sintetize as seguintes anÃ¡lises numa conclusÃ£o coerente:
        
        {texto_analises}
        
        ConclusÃ£o:
        """
        return self.llm(prompt)

# Criar sistema
agentes = [
    AgenteAnalitico("Ana", "AnÃ¡lise Financeira"),
    AgenteAnalitico("Bruno", "AnÃ¡lise de Mercado"),
    AgenteAnalitico("Carlos", "AnÃ¡lise TÃ©cnica")
]

# Analisar
dados = "Dados da empresa XYZ para Q4 2023..."
analises = [agente.analisar(dados) for agente in agentes]

# Sintetizar
sintetizador = Sintetizador()
conclusao = sintetizador.sintetizar(analises)
print(conclusao)
```

## ğŸ”Œ ReferÃªncia da API

### Endpoints Principais

#### GestÃ£o de Agentes

**GET** `/api/v1/agents`
- Listar todos os agentes
- Resposta: `{ "agents": [...], "total": 10 }`

**POST** `/api/v1/agents`
- Criar novo agente
- Body: `{ "name": "...", "type": "...", "config": {...} }`

**GET** `/api/v1/agents/{agent_id}`
- Obter detalhes de um agente

**PUT** `/api/v1/agents/{agent_id}`
- Atualizar agente

**DELETE** `/api/v1/agents/{agent_id}`
- Eliminar agente

#### ExecuÃ§Ã£o de Agentes

**POST** `/api/v1/agents/{agent_id}/execute`
- Executar agente
- Body: `{ "input": "...", "context": {...} }`
- Resposta: `{ "output": "...", "metadata": {...} }`

**POST** `/api/v1/agents/{agent_id}/stream`
- Executar agente com streaming
- Retorna: Server-Sent Events (SSE)

#### GestÃ£o de Fluxos de Trabalho

**GET** `/api/v1/workflows`
- Listar fluxos de trabalho

**POST** `/api/v1/workflows`
- Criar novo fluxo de trabalho

**POST** `/api/v1/workflows/{workflow_id}/execute`
- Executar fluxo de trabalho

#### Vector Store / RAG

**POST** `/api/v1/documents/upload`
- Fazer upload de documentos
- Body: `multipart/form-data`

**GET** `/api/v1/documents`
- Listar documentos indexados

**POST** `/api/v1/documents/search`
- Pesquisar documentos
- Body: `{ "query": "...", "limit": 10 }`

**DELETE** `/api/v1/documents/{doc_id}`
- Eliminar documento

#### MonitorizaÃ§Ã£o

**GET** `/api/v1/metrics`
- Obter mÃ©tricas do sistema

**GET** `/api/v1/metrics/agents/{agent_id}`
- MÃ©tricas de um agente especÃ­fico

**GET** `/api/v1/health`
- Estado de saÃºde do sistema

### AutenticaÃ§Ã£o

Todos os endpoints (exceto `/health`) requerem autenticaÃ§Ã£o via JWT:

```bash
# Obter token
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "user", "password": "pass"}'

# Usar token
curl -X GET http://localhost:8000/api/v1/agents \
  -H "Authorization: Bearer {seu_token}"
```

### Exemplos de UtilizaÃ§Ã£o

```python
import requests

# ConfiguraÃ§Ã£o
BASE_URL = "http://localhost:8000/api/v1"
TOKEN = "seu_token_jwt"

headers = {
    "Authorization": f"Bearer {TOKEN}",
    "Content-Type": "application/json"
}

# Criar agente
novo_agente = {
    "name": "Assistente de Vendas",
    "type": "supervisor",
    "config": {
        "llm": "gpt-4",
        "temperature": 0.7
    }
}

response = requests.post(
    f"{BASE_URL}/agents",
    json=novo_agente,
    headers=headers
)
agent_id = response.json()["id"]

# Executar agente
pergunta = {
    "input": "Quais sÃ£o os produtos mais vendidos?",
    "context": {"periodo": "ultimo_mes"}
}

response = requests.post(
    f"{BASE_URL}/agents/{agent_id}/execute",
    json=pergunta,
    headers=headers
)
resultado = response.json()
print(resultado["output"])
```

## ğŸ”§ ResoluÃ§Ã£o de Problemas

### Problemas Comuns

#### 1. Erro de ConexÃ£o Ã  Base de Dados

**Problema**: `connection refused` ou `database does not exist`

**SoluÃ§Ã£o**:
```bash
# Verificar se PostgreSQL estÃ¡ a correr
sudo systemctl status postgresql

# Criar base de dados se nÃ£o existir
createdb chakraagents

# Verificar configuraÃ§Ã£o no .env
# Formato: postgresql://utilizador:senha@host:porta/basededados
```

#### 2. Erro de API Key InvÃ¡lida

**Problema**: `Invalid API key` ou `401 Unauthorized`

**SoluÃ§Ã£o**:
- Verificar se a chave estÃ¡ correcta no ficheiro `.env`
- Confirmar que a chave tem permissÃµes adequadas
- Verificar se nÃ£o hÃ¡ espaÃ§os em branco na chave

```bash
# Verificar variÃ¡vel de ambiente
echo $OPENAI_API_KEY
```

#### 3. Erro de MemÃ³ria Insuficiente

**Problema**: `Out of memory` durante processamento de documentos

**SoluÃ§Ã£o**:
```python
# Reduzir tamanho dos chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # Reduzido de 1000
    chunk_overlap=50
)

# Processar documentos em lotes
for i in range(0, len(documentos), 10):
    lote = documentos[i:i+10]
    processar_lote(lote)
```

#### 4. LentidÃ£o na ExecuÃ§Ã£o

**Problema**: Agentes demoram muito tempo a responder

**SoluÃ§Ãµes**:
```python
# 1. Usar modelo mais rÃ¡pido
llm = OpenAI(model="gpt-3.5-turbo")  # em vez de gpt-4

# 2. Reduzir temperatura para respostas mais diretas
llm = OpenAI(temperature=0)

# 3. Implementar cache
from langchain.cache import InMemoryCache
langchain.llm_cache = InMemoryCache()

# 4. Limitar tokens de resposta
llm = OpenAI(max_tokens=500)
```

#### 5. Vector Store NÃ£o Encontra Documentos

**Problema**: Pesquisas nÃ£o retornam resultados relevantes

**SoluÃ§Ã£o**:
```python
# 1. Ajustar nÃºmero de resultados
retriever = vectorstore.as_retriever(
    search_kwargs={"k": 10}  # aumentar de 4 para 10
)

# 2. Usar pesquisa por similaridade com threshold
docs = vectorstore.similarity_search_with_score(
    pergunta,
    k=5,
    score_threshold=0.7
)

# 3. Reindexar documentos
vectorstore = Chroma.from_documents(
    documentos,
    embeddings,
    persist_directory="./chroma_db"
)
vectorstore.persist()
```

### Logs e Debug

#### Ativar Logs Detalhados

```python
import logging

# Configurar logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Logs de LangChain
from langchain.globals import set_debug
set_debug(True)
```

#### Ver Logs do Sistema

```bash
# Logs do backend
tail -f logs/app.log

# Logs do Docker (se usar)
docker-compose logs -f backend
```

## ğŸ¤ Contribuir

ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga estas diretrizes:

### Processo de ContribuiÃ§Ã£o

1. **Fork** o repositÃ³rio
2. **Clone** o seu fork
3. **Crie** um branch para a sua funcionalidade
4. **Implemente** as alteraÃ§Ãµes
5. **Teste** as suas alteraÃ§Ãµes
6. **Commit** com mensagens descritivas
7. **Push** para o seu fork
8. **Crie** um Pull Request

### Diretrizes de CÃ³digo

```python
# Seguir PEP 8 para Python
# Usar type hints
def processar_documento(doc: str, opcoes: Dict[str, Any]) -> Dict:
    """
    Processa um documento.
    
    Args:
        doc: O documento a processar
        opcoes: OpÃ§Ãµes de processamento
        
    Returns:
        Resultado do processamento
    """
    pass

# Documentar funÃ§Ãµes e classes
# Escrever testes unitÃ¡rios
def test_processar_documento():
    resultado = processar_documento("teste", {})
    assert resultado is not None
```

### Executar Testes

```bash
# Backend
cd backend
pytest tests/ -v

# Frontend
cd frontend
npm test

# Cobertura
pytest --cov=app tests/
```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Consulte o ficheiro `LICENSE` para mais detalhes.

---

## ğŸ“ Suporte e Comunidade

- **GitHub Issues**: [Reportar problemas](https://github.com/sudsk/ChakraAgents.ai/issues)
- **DocumentaÃ§Ã£o**: [Wiki do projeto](https://github.com/sudsk/ChakraAgents.ai/wiki)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/sudsk/ChakraAgents.ai/discussions)

## ğŸ™ Agradecimentos

Este projeto foi construÃ­do com base em:
- [LangChain](https://github.com/langchain-ai/langchain)
- [LangGraph](https://github.com/langchain-ai/langgraph)
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)
- [Chakra UI](https://chakra-ui.com/)

---

**Desenvolvido com â¤ï¸ pela comunidade ChakraAgents.ai**
