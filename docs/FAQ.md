# Perguntas Frequentes (FAQ)

Respostas √†s perguntas mais comuns sobre ChakraAgents.ai.

## √çndice

- [Geral](#geral)
- [Instala√ß√£o](#instala√ß√£o)
- [Configura√ß√£o](#configura√ß√£o)
- [Utiliza√ß√£o](#utiliza√ß√£o)
- [Resolu√ß√£o de Problemas](#resolu√ß√£o-de-problemas)
- [Licenciamento e Custos](#licenciamento-e-custos)

## Geral

### O que √© ChakraAgents.ai?

ChakraAgents.ai √© uma plataforma open-source para criar, testar e implementar sistemas de IA ag√™ntica. Permite construir agentes inteligentes que podem raciocinar, tomar decis√µes e colaborar de forma aut√≥noma.

### Qual a diferen√ßa entre ChakraAgents.ai e outras frameworks como LangChain?

ChakraAgents.ai √© constru√≠do sobre LangChain, mas adiciona:
- Interface visual para design de fluxos de trabalho
- M√∫ltiplas arquiteturas pr√©-configuradas (Supervisor, Swarm, RAG)
- API REST para deployment imediato
- Sistema de monitoriza√ß√£o integrado
- Gest√£o de documentos RAG simplificada

### ChakraAgents.ai √© gratuito?

Sim, ChakraAgents.ai √© open-source sob licen√ßa MIT. No entanto, ter√° custos associados:
- APIs dos LLMs (OpenAI, Anthropic, etc.)
- Infraestrutura (servidores, bases de dados)
- Servi√ßos cloud (se usar)

### Que fornecedores de LLM s√£o suportados?

Atualmente suporta:
- OpenAI (GPT-3.5, GPT-4, GPT-4-Turbo)
- Anthropic (Claude, Claude-2)
- Google (Vertex AI, PaLM)
- Modelos locais via Ollama
- Qualquer modelo compat√≠vel com OpenAI API

### Posso usar modelos locais sem custos de API?

Sim! Use Ollama ou modelos Hugging Face:

```python
from langchain.llms import Ollama

llm = Ollama(model="llama2")
agente = criar_agente(llm=llm)
```

## Instala√ß√£o

### Quais s√£o os requisitos m√≠nimos?

- **Hardware**: CPU 2 cores, 4GB RAM, 10GB disco
- **Software**: Python 3.10+, Node.js 16+, PostgreSQL 12+
- **Sistema Operativo**: Linux, macOS, ou Windows com WSL2

### A instala√ß√£o via Docker √© mais f√°cil?

Sim, Docker simplifica muito:

```bash
git clone https://github.com/sudsk/ChakraAgents.ai.git
cd ChakraAgents.ai
docker-compose up -d
```

Tudo fica configurado automaticamente.

### Posso instalar sem Docker?

Sim, siga o [Guia de Instala√ß√£o Manual](./guias/INSTALACAO.md#instala√ß√£o-manual).

### Quanto tempo demora a instala√ß√£o?

- Via Docker: 10-15 minutos
- Manual: 30-45 minutos (primeira vez)

### Como atualizar para vers√£o mais recente?

```bash
# Docker
docker-compose pull
docker-compose up -d

# Manual
git pull origin main
pip install -r requirements.txt --upgrade
npm install
alembic upgrade head
```

## Configura√ß√£o

### Onde coloco minhas chaves API?

No ficheiro `.env`:

```env
OPENAI_API_KEY=sk-sua-chave-aqui
ANTHROPIC_API_KEY=sk-ant-sua-chave-aqui
```

Nunca commit este ficheiro ao git!

### Como configurar m√∫ltiplos ambientes?

Crie ficheiros `.env` separados:

```bash
.env.development
.env.staging
.env.production
```

E carregue conforme ambiente:

```python
from dotenv import load_dotenv
import os

ambiente = os.getenv('AMBIENTE', 'development')
load_dotenv(f'.env.{ambiente}')
```

### Posso usar base de dados diferente de PostgreSQL?

Sim, suporta qualquer BD compat√≠vel com SQLAlchemy:
- PostgreSQL (recomendado)
- MySQL/MariaDB
- SQLite (apenas desenvolvimento)

### Como configurar SSL/HTTPS?

Use Nginx ou Traefik como reverse proxy:

```nginx
server {
    listen 443 ssl;
    server_name seu-dominio.com;
    
    ssl_certificate /caminho/cert.pem;
    ssl_certificate_key /caminho/key.pem;
    
    location / {
        proxy_pass http://localhost:8000;
    }
}
```

## Utiliza√ß√£o

### Como criar meu primeiro agente?

Siga o [Tutorial Primeiro Agente](./tutoriais/PRIMEIRO_AGENTE.md).

Resumo r√°pido:
1. Aceda √† interface web
2. Clique "Novo Agente"
3. Configure nome e tipo
4. Adicione ferramentas
5. Teste

### Qual arquitetura devo escolher?

Depende do caso de uso:
- **Supervisor**: Fluxos sequenciais bem definidos
- **Swarm**: Problemas que requerem m√∫ltiplas perspectivas
- **RAG**: Respostas baseadas em documentos

Veja [Guia de Arquiteturas](./guias/ARQUITETURAS.md) para detalhes.

### Como adicionar documentos para RAG?

Via API:

```bash
curl -X POST http://localhost:8000/api/v1/documents/upload \
  -H "Authorization: Bearer {token}" \
  -F "files=@documento.pdf"
```

Ou programaticamente:

```python
sistema_rag = SistemaRAG("./documentos")
sistema_rag.adicionar_documentos(["novo conte√∫do"])
```

### Como implementar agente em produ√ß√£o?

1. Criar agente e testar
2. Usar endpoint `/agents/{id}/execute`
3. Implementar como API REST
4. Configurar monitoriza√ß√£o

Veja [Guia de Deployment](./guias/BOAS_PRATICAS.md#deployment).

### Como manter contexto entre perguntas?

Use mem√≥ria conversacional:

```python
from langchain.memory import ConversationBufferMemory

memoria = ConversationBufferMemory()
agente = initialize_agent(
    ferramentas,
    llm,
    memory=memoria
)
```

### Posso integrar com sistemas existentes?

Sim! ChakraAgents.ai fornece:
- API REST completa
- Webhooks para eventos
- SDKs para Python e JavaScript
- Documenta√ß√£o OpenAPI

## Resolu√ß√£o de Problemas

### "Connection refused" ao iniciar

**Problema**: Servi√ßo n√£o iniciou corretamente

**Solu√ß√µes**:
1. Verifique se porta est√° dispon√≠vel: `lsof -i :8000`
2. Veja logs: `docker-compose logs backend`
3. Verifique vari√°veis de ambiente

### "Invalid API key"

**Problema**: Chave OpenAI/Anthropic inv√°lida

**Solu√ß√µes**:
1. Verifique chave no `.env`
2. Confirme que chave est√° ativa
3. Teste chave diretamente:

```python
import openai
openai.api_key = "sua-chave"
openai.Model.list()
```

### Agente responde muito devagar

**Causas comuns**:
- Modelo muito grande (GPT-4)
- Muitos documentos RAG
- Contexto muito longo

**Solu√ß√µes**:
1. Use modelo mais r√°pido (GPT-3.5)
2. Limite documentos RAG (top-k menor)
3. Reduza hist√≥rico de conversa√ß√£o
4. Implemente cache

### Respostas inconsistentes

**Problema**: Agente d√° respostas diferentes

**Solu√ß√µes**:
1. Reduza temperatura: `temperature=0`
2. Seja mais espec√≠fico no prompt
3. Use exemplos (few-shot)
4. Adicione valida√ß√µes

### "Out of memory"

**Problema**: Mem√≥ria insuficiente

**Solu√ß√µes**:
1. Reduza tamanho de chunks RAG
2. Processe em lotes menores
3. Aumente RAM do servidor
4. Use pagina√ß√£o

### Docker n√£o inicia

**Problema**: Erro ao iniciar containers

**Solu√ß√µes**:
1. Verifique Docker est√° a correr: `docker ps`
2. Reconstrua imagens: `docker-compose build --no-cache`
3. Limpe volumes antigos: `docker-compose down -v`
4. Veja logs detalhados: `docker-compose logs -f`

### Base de dados n√£o conecta

**Problema**: Erro de conex√£o PostgreSQL

**Solu√ß√µes**:
1. Verifique se PostgreSQL est√° a correr
2. Confirme credenciais no `.env`
3. Teste conex√£o:

```bash
psql -U user -d chakraagents -h localhost
```

### "Module not found"

**Problema**: Depend√™ncia Python faltando

**Solu√ß√£o**:

```bash
pip install -r requirements.txt --force-reinstall
```

### Frontend n√£o carrega

**Problemas comuns**:

```bash
# Limpar cache
rm -rf node_modules package-lock.json
npm cache clean --force
npm install

# Verificar porta
lsof -i :3000

# Verificar env
cat frontend/.env
```

## Licenciamento e Custos

### ChakraAgents.ai tem custos?

A plataforma √© gratuita (open-source), mas h√° custos:

**Custos de APIs LLM**:
- OpenAI: $0.002/1K tokens (GPT-3.5) a $0.06/1K (GPT-4)
- Anthropic: Similar ao OpenAI
- Modelos locais: Gr√°tis (mas custos de hardware)

**Custos de Infraestrutura**:
- Servidor: ‚Ç¨5-50/m√™s (VPS b√°sico)
- Base de dados: Inclu√≠do ou ‚Ç¨5-20/m√™s
- Armazenamento: ‚Ç¨0.01-0.10/GB/m√™s

**Estimativa mensal (pequeno projeto)**:
- APIs LLM: ‚Ç¨10-50
- Servidor: ‚Ç¨10-20
- Total: ‚Ç¨20-70/m√™s

### Como reduzir custos?

1. **Use modelos mais baratos**:
   - GPT-3.5 em vez de GPT-4
   - Modelos locais quando poss√≠vel

2. **Implemente cache**:
   - Cachear perguntas frequentes
   - Usar Redis

3. **Otimize prompts**:
   - Prompts mais curtos
   - Menos exemplos few-shot

4. **Limite contexto**:
   - Reduzir hist√≥rico conversacional
   - Top-k menor em RAG

5. **Monitorize uso**:
   - Alertas de custos
   - Limites por utilizador

### Posso usar comercialmente?

Sim! Licen√ßa MIT permite uso comercial. No entanto:
- Respeite termos de uso dos LLMs
- Implemente medidas de seguran√ßa
- Considere liability/garantias

### Preciso de suporte enterprise?

Para suporte dedicado, considere:
- Consultoria especializada
- SLAs garantidos
- Desenvolvimento personalizado
- Forma√ß√£o de equipas

Contacte: enterprise@chakraagents.ai

## Contribuir e Comunidade

### Como contribuir?

1. Fork o reposit√≥rio
2. Crie branch para funcionalidade
3. Implemente com testes
4. Submeta Pull Request

Veja [Guia de Contribui√ß√£o](../CONTRIBUTING.md).

### Onde obter ajuda?

- üí¨ [Discord](https://discord.gg/chakraagents)
- üìß Email: support@chakraagents.ai
- üêõ [GitHub Issues](https://github.com/sudsk/ChakraAgents.ai/issues)
- üìö [Documenta√ß√£o](../README.md)

### Como reportar bug?

Abra issue no GitHub com:
- Descri√ß√£o do problema
- Passos para reproduzir
- Comportamento esperado vs atual
- Vers√£o e ambiente
- Logs relevantes

### Posso sugerir funcionalidades?

Sim! Abra discuss√£o no GitHub:
- Descreva funcionalidade
- Caso de uso
- Benef√≠cios esperados
- Implementa√ß√£o sugerida (opcional)

## Quest√µes T√©cnicas Avan√ßadas

### Como escalar horizontalmente?

Use m√∫ltiplas inst√¢ncias com load balancer:

```yaml
# docker-compose.scale.yml
services:
  backend:
    deploy:
      replicas: 3
  
  nginx:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

### Como implementar autentica√ß√£o custom?

Estenda sistema de autentica√ß√£o:

```python
from fastapi_users import FastAPIUsers

fastapi_users = FastAPIUsers(
    get_user_manager,
    [auth_backend],
)

app.include_router(
    fastapi_users.get_auth_router(auth_backend),
    prefix="/auth",
)
```

### Como adicionar fornecedor LLM custom?

Implemente interface LangChain:

```python
from langchain.llms.base import LLM

class MeuLLMCustom(LLM):
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        # Sua l√≥gica aqui
        return resposta
    
    @property
    def _llm_type(self) -> str:
        return "custom"
```

### Suporta m√∫ltiplas l√≠nguas?

Sim! LLMs modernos s√£o multil√≠ngues. Configure:

```python
prompt_template = """
Responda sempre em {lingua}.

Pergunta: {pergunta}
"""
```

### Como implementar fine-tuning?

ChakraAgents.ai usa LLMs via API. Para fine-tuning:

1. Colete dados de treino
2. Use plataforma do fornecedor (OpenAI, etc.)
3. Configure agente para usar modelo fine-tuned

```python
llm = OpenAI(model="ft:gpt-3.5-turbo:seu-modelo")
```

---

**N√£o encontrou sua pergunta?**

- Consulte [Documenta√ß√£o Completa](../README.md)
- Pergunte no [Discord](https://discord.gg/chakraagents)
- Abra [Issue no GitHub](https://github.com/sudsk/ChakraAgents.ai/issues)
